{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd5744d",
   "metadata": {},
   "source": [
    "# Starting off:\n",
    "## Transform your parquet file to csv: (Change CSV name accordingly.)\n",
    "# Use: prqt_to_csv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5715adc9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('yellow_tripdata_2020-01.parquet')\n",
    "df.to_csv('tripdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f81e15b",
   "metadata": {},
   "source": [
    "# Separating the files.\n",
    "## Stores filtered rows by dates: (have a main_file *transformed CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83464671",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "\n",
    "src_path = \"\"\n",
    "main_file = \"./tripdata.csv.\"  # Your csv file here\n",
    "choose_filter_date = \"2020-01\"\n",
    "\n",
    "# Opens the file and sorts the relevant/invalid dates.\n",
    "with open(main_file, \"rt\") as fp:\n",
    "    root = csv.reader(fp, delimiter=\",\")\n",
    "    result = collections.defaultdict(list)\n",
    "    invalid = collections.defaultdict(list)\n",
    "    next(root)\n",
    "    for row in root:\n",
    "        date = row[3].split(\" \")\n",
    "        if date[0].startswith(choose_filter_date + \"-\"):  # Choose_filter_date f.e. =2020-02\n",
    "            result[date[0]].append(row)\n",
    "        else:\n",
    "            invalid[date[0]].append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1cd72",
   "metadata": {},
   "source": [
    "## Stores column values to be used for each new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0cdf83e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Grabs the column names, to later inject into new files\n",
    "with open('./test.csv') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=\",\")\n",
    "    col_names = []\n",
    "    for row in csv_reader:\n",
    "        col_names.append(row)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb0bf3",
   "metadata": {},
   "source": [
    "## Creates the new files: (res= choose what you want written *result or invalid) (pth=your pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9eaf4e2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates files using the results and your chosen path\n",
    "def write_files(res, pth):\n",
    "    for i, j in res.items():  # res= result or invalid\n",
    "        file_path = \"./\" + pth + \"/%s%s.csv\" % (src_path, i)  # Changes pth to where you will store CSV files\n",
    "        with open(file_path, 'wt') as new_file:\n",
    "            writer = csv.writer(new_file, delimiter=\",\")\n",
    "            writer.writerows(col_names)\n",
    "            writer.writerows(j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b444224",
   "metadata": {},
   "source": [
    "## Run the functions with appropraite params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c141d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_files(invalid, \"invalid_dates\")\n",
    "write_files(result, \"january\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d607dad",
   "metadata": {},
   "source": [
    "# Loader.py:\n",
    "## Loads your chosen files into SQLite (choose path and file at bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec439f7b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "def load_directory(dirname, db):\n",
    "    for filename in glob.glob(os.path.join(dirname, '*.csv')):\n",
    "        load_file(filename, db)\n",
    "\n",
    "def load_file(filename, db):\n",
    "        with open(filename) as file:\n",
    "            with db:\n",
    "                data = csv.DictReader(file)\n",
    "                cols = data.fieldnames\n",
    "                table = os.path.splitext(os.path.basename(filename))[0]\n",
    "\n",
    "                sql = 'drop table if exists \"{}\"'.format(table)\n",
    "                db.execute(sql)\n",
    "\n",
    "                sql = 'create table \"{table}\" ( {cols} )'.format(\n",
    "                    table=table,\n",
    "                    cols=','.join('\"{}\"'.format(col) for col in cols))\n",
    "                db.execute(sql)\n",
    "\n",
    "                sql = 'insert into \"{table}\" values ( {vals} )'.format(\n",
    "                    table=table,\n",
    "                    vals=','.join('?' for col in cols))\n",
    "                db.executemany(sql, (list(map(row.get, cols)) for row in data))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conn = sqlite3.connect('january_trips.db')\n",
    "    load_directory('./january', conn)\n",
    "    \n",
    "    \n",
    "# Optional for injection of invalid_dates\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     conn = sqlite3.connect('invalid.db')\n",
    "#     load_directory('./invalid_dates', conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
